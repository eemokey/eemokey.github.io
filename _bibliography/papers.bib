---
---

@string{aps = {American Physical Society,}}




@article{firstphdpaper,
  title={Transferable and Interpretable Treatment Effectiveness Prediction for Ovarian Cancer via Multimodal Deep Learning},
  author={Nguyen, Emily and Cui, Zijun and Kokaraki, Georgia and Carlson, Joseph and Liu, Yan},
  abstract={Ovarian cancer, a potentially life-threatening disease, is often difficult to treat. There is a critical need for innovations that can assist in improved therapy selection. Although deep learning models are showing promising results, they are employed as a "black-box" and require enormous amounts of data. Therefore, we explore the transferable and interpretable prediction of treatment effectiveness for ovarian cancer patients. Unlike existing works focusing on histopathology images, we propose a multimodal deep learning framework which takes into account not only large histopathology images, but also clinical variables to increase the scope of the data. The results demonstrate that the proposed models achieve high prediction accuracy and interpretability, and can also be transferred to other cancer datasets without significant loss of performance.},
  journal={American Medical Informatics Association Symposium (AMIA)},
  year={2023},
  preview={wsi_heatmapsample2.jpeg},
  selected={true}
}

@article{bathesis,
  title={Machine Learning Methods for Supervised Classification of Behavioral Time Series Data},
  author={Nguyen, Emily},
  abstract={Quantitative analysis of continuously recorded behavioral data entails both classification and segregation of the constituent unique behavioral phenotypes to avoid potential confounds. Current methods utilize human or sensor-based annotation to perform this task. A deep learning approach using supervised classification is developed to automate this time-consuming process, predicting unique hierarchical behavioral phenotypes with high accuracy. Additionally, network ensembles are utilized to enhance the robustness and accuracy of supervised classification, as well as to identify potential outliers when using the classifier in the field.},
  html={https://reachmaster.readthedocs.io/en/latest/software/ReachSplitter/ReachSplitter.html},
  journal={University of California, Berkeley, Department of Electrical Engineering and Computer Science (B.A. Honors Thesis)},
  month={May},
  year={2022},
  preview={bimanreach_timeseries_full.gif},
  selected={true}
}

@article{reachmaster3d,
  title={ReachMaster-3D: An Experimental Platform for Precise 3D Measurement of Whole-Arm Kinematics During Freely-Behaving Reaches in Rats},
  author={Nelson, Brett and Ibraheem, Shafeeq and Nguyen, Emily and Bouchard, Kristofer},
  abstract={Reaching is an essential behavior occurring in three dimensions (3-D). Rodents perform dexterous reaching behaviors, however rodent reaching has mainly been quantified during low-dimensional behavioral tasks and resulting kinematic measurements are not-in 3-D. There exists a need for behavioral assays, using high-dimensional tasks, to measure whole-arm reaching kinematic variables in 3-D during freely-behaving reaching. Here we present ReachMaster-3D, a novel assay capable of measuring reaching 3-D kinematics from freely-behaving male rats reaching to a handle varied in position from 0 to 3 task dimensions. We examine measures of task performance and effect of task complexity on trajectories and velocities extracted using the ReachSplitter-3D system. We then use 3-D kinematic variables within current motor control models to quantify the effects of task dimension on kinematic variability. 
ReachMaster and the accompanying ReachSplitter3D library produce robust (<4mm) 3-D kinematic (position, velocity, acceleration) predictions across 27 unique whole-arm and body segments during continuous reaching experiments in an unsupervised manner. To perform this task we developed a behavioral classification pipeline to classify and finely segment reaching behaviors using supervised learning. Using as inputs 3-D kinematics and accompanying sensor data from the ReachMaster assay into a set of pre trained random forest classification algorithms that separate out unique reaching phenotypes at sub-millisecond temporal resolution, we show that ReachSplitter-3D reliably distinguishes between behavioral subtypes during reaching. We then present a model that performs event detection and segmentation within our high-dimensional time-series datasets. We analyze resulting segmented kinematics across similar reaching classes using trajectory minimization and second-order feedback control models across two unique task paradigms. Our central hypothesis is that modulation of task dimension structures variability in the 3-D kinematics of rodents. Our current research extends the current understanding of freely-behaving rats reaching in 3-D task environments, necessary for modern translational research in kinesiology and neurophysiology of reaching that seeks to fully rehabilitate or restore natural reaching behavior in humans. Our future research will seek to uncover cortical surface representations of kinematic variables during reaching in rodents utilizing the novel research methods shown.},
  html={https://reachmaster.readthedocs.io/en/latest/overview.html},
  journal={Society for Neuroscience (SfN)},
  year={2021},
  preview={failed_reach_gif.gif}, 
  selected={true}
}
