<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Emily Nguyen</title> <meta name="author" content="Emily Nguyen"> <meta name="description" content="Emily Nguyen "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://eemokey.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?96d6b3e1c3604aca8b6134c7afdd5db6"></script> <script src="/assets/js/dark_mode.js?9b17307bb950ffa2e34be0227f53558f"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Home<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/assets/pdf/ENguyen_CV_pdf.pdf">CV</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/contact/">Contact</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Emily</span> Nguyen </h1> <p class="desc"><a href="#">(she/her/hers)</a> emilyn98@usc.edu</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/prof_pic-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/prof_pic-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/prof_pic-1400.webp"></source> <img src="/assets/img/prof_pic.jpg?96296b78c3606f5d8de2d4325b27b905" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="prof_pic.jpg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="address"> <p>Nice To Meet You</p> </div> </div> <div class="clearfix"> <p>Hello, I’m Emily. I am a 2nd year PhD student at the <a href="https://melady.usc.edu/" rel="external nofollow noopener" target="_blank">Melady Lab</a> in the <a href="https://www.cs.usc.edu/" rel="external nofollow noopener" target="_blank">Thomas Lord Computer Science Department</a> at the <a href="https://www.usc.edu/" rel="external nofollow noopener" target="_blank">University of Southern California</a>. I am fortunate to be advised by Professor <a href="https://viterbi-web.usc.edu/~liu32/" rel="external nofollow noopener" target="_blank">Yan Liu</a> and supported by the <a href="https://www.nsfgrfp.org/" rel="external nofollow noopener" target="_blank">NSF GRFP</a>.</p> <p>I do research on machine learning for data with special structure, such as time series, with applications to health, healthcare, and environmental science. I also enjoy figure skating, flower arranging, sunset walks around campus, and frequent visits to my hometown in San Diego.</p> <p>Prior to USC, I studied <a href="https://eecs.berkeley.edu/academics/undergraduate/cs-ba" rel="external nofollow noopener" target="_blank">computer science</a> with an emphasis in computational neuroscience at <a href="https://www.berkeley.edu/" rel="external nofollow noopener" target="_blank">UC Berkeley</a> and was an undergraduate researcher at <a href="https://www.lbl.gov/" rel="external nofollow noopener" target="_blank">Lawrence Berkeley National Laboratory</a> and <a href="https://www.ucsf.edu/" rel="external nofollow noopener" target="_blank">UCSF</a>. My co-advisors were Professors <a href="https://bouchardlab.lbl.gov/" rel="external nofollow noopener" target="_blank">Kristofer Bouchard</a> and <a href="https://roybens.faculty.ucdavis.edu/" rel="external nofollow noopener" target="_blank">Roy Ben-Shalom</a>.</p> <p>I welcome all efforts to <a href="https://eemokey.github.io/contact/">get in touch with me</a>.</p> </div> <h2><a href="/news/" style="color: inherit;">news</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Jul 10, 2023</th> <td> The first paper of my PhD was accepted to <a href="https://amia.org/education-events/amia-2023-annual-symposium" rel="external nofollow noopener" target="_blank">AMIA</a>! </td> </tr> <tr> <th scope="row">Jun 6, 2023</th> <td> Our project was featured on the local news <a href="https://spectrumnews1.com/ca/la-west/education/2023/06/06/usc-invests--1-billion-into-advancing-computing-research--curriculum" rel="external nofollow noopener" target="_blank">(article)</a>. </td> </tr> <tr> <th scope="row">Apr 25, 2023</th> <td> It is an honor to be a recipient of the <a href="https://viterbischool.usc.edu/news/2023/07/usc-computer-science-students-awarded-nsf-graduate-research-fellowships/" rel="external nofollow noopener" target="_blank">NSF GRFP</a>. </td> </tr> </table> </div> </div> <h2><a href="/publications/" style="color: inherit;">selected publications</a></h2> <div class="publications"> <h2 class="bibliography">2023</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/wsi_heatmapsample2_gif.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/wsi_heatmapsample2_gif.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/wsi_heatmapsample2_gif.gif-1400.webp"></source> <img src="/assets/img/publication_preview/wsi_heatmapsample2_gif.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="wsi_heatmapsample2_gif.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="firstphdpaper" class="col-sm-8"> <div class="title">Transferable and Interpretable Treatment Effectiveness Prediction for Ovarian Cancer via Multimodal Deep Learning</div> <div class="author"> <em>Emily Nguyen</em>, Zijun Cui, Georgia Kokaraki, Joseph Carlson, and Yan Liu</div> <div class="periodical"> <em>American Medical Informatics Association Symposium (AMIA)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Ovarian cancer, a potentially life-threatening disease, is often difficult to treat. There is a critical need for innovations that can assist in improved therapy selection. Although deep learning models are showing promising results, they are employed as a "black-box" and require enormous amounts of data. Therefore, we explore the transferable and interpretable prediction of treatment effectiveness for ovarian cancer patients. Unlike existing works focusing on histopathology images, we propose a multimodal deep learning framework which takes into account not only large histopathology images, but also clinical variables to increase the scope of the data. The results demonstrate that the proposed models achieve high prediction accuracy and interpretability, and can also be transferred to other cancer datasets without significant loss of performance.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/bimanreach_timeseries_full.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/bimanreach_timeseries_full.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/bimanreach_timeseries_full.gif-1400.webp"></source> <img src="/assets/img/publication_preview/bimanreach_timeseries_full.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="bimanreach_timeseries_full.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="bathesis" class="col-sm-8"> <div class="title">Machine Learning Methods for Supervised Classification of Behavioral Time Series Data</div> <div class="author"> <em>Emily Nguyen</em> </div> <div class="periodical"> <em>University of California, Berkeley, Department of Electrical Engineering and Computer Science (B.A. Honors Thesis)</em>, May 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://reachmaster.readthedocs.io/en/latest/software/ReachSplitter/ReachSplitter.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Quantitative analysis of continuously recorded behavioral data entails both classification and segregation of the constituent unique behavioral phenotypes to avoid potential confounds. Current methods utilize human or sensor-based annotation to perform this task. A deep learning approach using supervised classification is developed to automate this time-consuming process, predicting unique hierarchical behavioral phenotypes with high accuracy. Additionally, network ensembles are utilized to enhance the robustness and accuracy of supervised classification, as well as to identify potential outliers when using the classifier in the field.</p> </div> </div> </div> </li></ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/failed_reach_gif.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/failed_reach_gif.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/failed_reach_gif.gif-1400.webp"></source> <img src="/assets/img/publication_preview/failed_reach_gif.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="failed_reach_gif.gif" data-zoomable onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="reachmaster3d" class="col-sm-8"> <div class="title">ReachMaster-3D: An Experimental Platform for Precise 3D Measurement of Whole-Arm Kinematics During Freely-Behaving Reaches in Rats</div> <div class="author"> Brett Nelson, Shafeeq Ibraheem, <em>Emily Nguyen</em>, and Kristofer Bouchard</div> <div class="periodical"> <em>Society for Neuroscience (SfN)</em>, May 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://reachmaster.readthedocs.io/en/latest/overview.html" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> </div> <div class="badges"> <span class="altmetric-embed" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> </div> <div class="abstract hidden"> <p>Reaching is an essential behavior occurring in three dimensions (3-D). Rodents perform dexterous reaching behaviors, however rodent reaching has mainly been quantified during low-dimensional behavioral tasks and resulting kinematic measurements are not-in 3-D. There exists a need for behavioral assays, using high-dimensional tasks, to measure whole-arm reaching kinematic variables in 3-D during freely-behaving reaching. Here we present ReachMaster-3D, a novel assay capable of measuring reaching 3-D kinematics from freely-behaving male rats reaching to a handle varied in position from 0 to 3 task dimensions. We examine measures of task performance and effect of task complexity on trajectories and velocities extracted using the ReachSplitter-3D system. We then use 3-D kinematic variables within current motor control models to quantify the effects of task dimension on kinematic variability. ReachMaster and the accompanying ReachSplitter3D library produce robust (&lt;4mm) 3-D kinematic (position, velocity, acceleration) predictions across 27 unique whole-arm and body segments during continuous reaching experiments in an unsupervised manner. To perform this task we developed a behavioral classification pipeline to classify and finely segment reaching behaviors using supervised learning. Using as inputs 3-D kinematics and accompanying sensor data from the ReachMaster assay into a set of pre trained random forest classification algorithms that separate out unique reaching phenotypes at sub-millisecond temporal resolution, we show that ReachSplitter-3D reliably distinguishes between behavioral subtypes during reaching. We then present a model that performs event detection and segmentation within our high-dimensional time-series datasets. We analyze resulting segmented kinematics across similar reaching classes using trajectory minimization and second-order feedback control models across two unique task paradigms. Our central hypothesis is that modulation of task dimension structures variability in the 3-D kinematics of rodents. Our current research extends the current understanding of freely-behaving rats reaching in 3-D task environments, necessary for modern translational research in kinesiology and neurophysiology of reaching that seeks to fully rehabilitate or restore natural reaching behavior in humans. Our future research will seek to uncover cortical surface representations of kinematic variables during reaching in rodents utilizing the novel research methods shown.</p> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Emily Nguyen. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>